{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JguZ3NBZUkpo"
   },
   "source": [
    "# Introduction to Convolutional Neural Networks (convnets or CNNs) with tf.keras and tf.data.\n",
    "\n",
    "For this notebook we will look at a convnet problem for image classification. Like the first two tutorials, we will classify Fashion-MNIST digits. This tutorial was inspired by [this one](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.1-introduction-to-convnets.ipynb).\n",
    "\n",
    "For the image classification task, rather than unstacking our images as we did in the previous notebooks, it is better to utilize the 2D structure of natural images and train on that. This is what convnets or CNNs do. On a very high level convnets are stacks of Convolutional layers (`Conv2D`) and Pooling layers (`MaxPooling2D`). But most importantly we will take as input 3D tensors of shape (`height`, `width`, `channels`) where for the case of grayscale images `channels=1` and return 3D tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qWT31nsxURdJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vNCKRyhQVSWO"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5eDlt-AnVafg"
   },
   "outputs": [],
   "source": [
    "TRAINING_SIZE = len(train_images)\n",
    "TEST_SIZE = len(test_images)\n",
    "\n",
    "train_images = np.asarray(train_images, dtype=np.float32) / 255\n",
    "\n",
    "# Convert the train images and add channels\n",
    "train_images = train_images.reshape((TRAINING_SIZE, 28, 28, 1))\n",
    "\n",
    "test_images = np.asarray(test_images, dtype=np.float32) / 255\n",
    "# Convert the train images and add channels\n",
    "test_images = test_images.reshape((TEST_SIZE, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YNi4TNvlVcIB"
   },
   "outputs": [],
   "source": [
    "# How many categories we are predicting from (0-9)\n",
    "LABEL_DIMENSIONS = 10\n",
    "\n",
    "train_labels  = tf.keras.utils.to_categorical(train_labels, LABEL_DIMENSIONS)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, LABEL_DIMENSIONS)\n",
    "\n",
    "# Cast the labels to floats, needed later\n",
    "train_labels = train_labels.astype(np.float32)\n",
    "test_labels = test_labels.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iHaND5a6Vc-B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=tf.nn.relu, input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=tf.nn.relu))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see above that the output of every convolutional layer is a 3D tensor of shape (`height`, `width`, `filters`). The width and height tend to get smaller as we go deeper into the network and the number of filters or channels increases from the input channel size of 1. \n",
    "\n",
    "The last part of the network for the classification task is similar to the other notebooks and consists of `Dense` layers which process 1D vectors. So we first need to `Flatten` our 3D outputs from the convolutional part to 1D and then add the `Dense` layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8EOBhY6xVd1S"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(LABEL_DIMENSIONS, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the network is again similar to all the previous notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SVUAOoeXVfQA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8jpqP9JYVgxM"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "\n",
    "# Because tf.data may work with potentially **large** collections of data\n",
    "# we do not shuffle the entire dataset by default\n",
    "# Instead, we maintain a buffer of SHUFFLE_SIZE elements\n",
    "# and sample from there.\n",
    "SHUFFLE_SIZE = 10000 \n",
    "\n",
    "# Create the dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "dataset = dataset.shuffle(SHUFFLE_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jvDEbM1DVigY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.09375\n",
      "10 0.4609375\n",
      "20 0.5234375\n",
      "30 0.5703125\n",
      "40 0.765625\n",
      "50 0.65625\n",
      "60 0.6953125\n",
      "70 0.671875\n",
      "80 0.734375\n",
      "90 0.734375\n",
      "100 0.640625\n",
      "110 0.6953125\n",
      "120 0.7421875\n",
      "130 0.828125\n",
      "140 0.8515625\n",
      "150 0.828125\n",
      "160 0.75\n",
      "170 0.703125\n",
      "180 0.75\n",
      "190 0.7734375\n",
      "200 0.7421875\n",
      "210 0.8046875\n",
      "220 0.7265625\n",
      "230 0.8203125\n",
      "240 0.875\n",
      "250 0.796875\n",
      "260 0.828125\n",
      "270 0.8125\n",
      "280 0.8046875\n",
      "290 0.8515625\n",
      "300 0.8359375\n",
      "310 0.8359375\n",
      "320 0.8203125\n",
      "330 0.8203125\n",
      "340 0.8359375\n",
      "350 0.7890625\n",
      "360 0.8125\n",
      "370 0.8125\n",
      "380 0.7421875\n",
      "390 0.8828125\n",
      "400 0.828125\n",
      "410 0.859375\n",
      "420 0.84375\n",
      "430 0.828125\n",
      "440 0.796875\n",
      "450 0.7890625\n",
      "460 0.8671875\n",
      "Epoch #1\t Loss: 0.482308\tAccuracy: 0.802083\n",
      "0 0.8125\n",
      "10 0.828125\n",
      "20 0.8671875\n",
      "30 0.8984375\n",
      "40 0.8515625\n",
      "50 0.84375\n",
      "60 0.828125\n",
      "70 0.8359375\n",
      "80 0.828125\n",
      "90 0.90625\n",
      "100 0.8046875\n",
      "110 0.8671875\n",
      "120 0.8125\n",
      "130 0.8515625\n",
      "140 0.90625\n",
      "150 0.8984375\n",
      "160 0.828125\n",
      "170 0.84375\n",
      "180 0.8515625\n",
      "190 0.921875\n",
      "200 0.8203125\n",
      "210 0.828125\n",
      "220 0.8046875\n",
      "230 0.875\n",
      "240 0.8984375\n",
      "250 0.84375\n",
      "260 0.8828125\n",
      "270 0.8671875\n",
      "280 0.84375\n",
      "290 0.890625\n",
      "300 0.8671875\n",
      "310 0.8515625\n",
      "320 0.90625\n",
      "330 0.8359375\n",
      "340 0.8828125\n",
      "350 0.828125\n",
      "360 0.9140625\n",
      "370 0.8359375\n",
      "380 0.7890625\n",
      "390 0.890625\n",
      "400 0.8671875\n",
      "410 0.875\n",
      "420 0.8671875\n",
      "430 0.875\n",
      "440 0.859375\n",
      "450 0.8125\n",
      "460 0.8984375\n",
      "Epoch #2\t Loss: 0.408985\tAccuracy: 0.854167\n",
      "0 0.859375\n",
      "10 0.84375\n",
      "20 0.8828125\n",
      "30 0.921875\n",
      "40 0.8828125\n",
      "50 0.890625\n",
      "60 0.8828125\n",
      "70 0.8828125\n",
      "80 0.8671875\n",
      "90 0.9296875\n",
      "100 0.8515625\n",
      "110 0.875\n",
      "120 0.890625\n",
      "130 0.9140625\n",
      "140 0.921875\n",
      "150 0.90625\n",
      "160 0.859375\n",
      "170 0.875\n",
      "180 0.875\n",
      "190 0.921875\n",
      "200 0.828125\n",
      "210 0.8359375\n",
      "220 0.8359375\n",
      "230 0.8828125\n",
      "240 0.9140625\n",
      "250 0.859375\n",
      "260 0.890625\n",
      "270 0.8828125\n",
      "280 0.8515625\n",
      "290 0.8984375\n",
      "300 0.9140625\n",
      "310 0.859375\n",
      "320 0.9140625\n",
      "330 0.875\n",
      "340 0.921875\n",
      "350 0.875\n",
      "360 0.9375\n",
      "370 0.84375\n",
      "380 0.8203125\n",
      "390 0.8828125\n",
      "400 0.8828125\n",
      "410 0.8671875\n",
      "420 0.890625\n",
      "430 0.8671875\n",
      "440 0.890625\n",
      "450 0.8828125\n",
      "460 0.9140625\n",
      "Epoch #3\t Loss: 0.348678\tAccuracy: 0.854167\n",
      "0 0.875\n",
      "10 0.859375\n",
      "20 0.90625\n",
      "30 0.9296875\n",
      "40 0.921875\n",
      "50 0.875\n",
      "60 0.875\n",
      "70 0.890625\n",
      "80 0.8984375\n",
      "90 0.953125\n",
      "100 0.84375\n",
      "110 0.8984375\n",
      "120 0.890625\n",
      "130 0.9296875\n",
      "140 0.9296875\n",
      "150 0.921875\n",
      "160 0.8671875\n",
      "170 0.90625\n",
      "180 0.8828125\n",
      "190 0.9296875\n",
      "200 0.8359375\n",
      "210 0.8515625\n",
      "220 0.8359375\n",
      "230 0.90625\n",
      "240 0.9140625\n",
      "250 0.9140625\n",
      "260 0.9140625\n",
      "270 0.8828125\n",
      "280 0.8515625\n",
      "290 0.9140625\n",
      "300 0.9140625\n",
      "310 0.8671875\n",
      "320 0.9375\n",
      "330 0.875\n",
      "340 0.921875\n",
      "350 0.8828125\n",
      "360 0.921875\n",
      "370 0.8828125\n",
      "380 0.828125\n",
      "390 0.890625\n",
      "400 0.8984375\n",
      "410 0.8828125\n",
      "420 0.8984375\n",
      "430 0.8828125\n",
      "440 0.90625\n",
      "450 0.890625\n",
      "460 0.9140625\n",
      "Epoch #4\t Loss: 0.300647\tAccuracy: 0.906250\n",
      "0 0.8671875\n",
      "10 0.8515625\n",
      "20 0.90625\n",
      "30 0.9453125\n",
      "40 0.921875\n",
      "50 0.890625\n",
      "60 0.890625\n",
      "70 0.90625\n",
      "80 0.90625\n",
      "90 0.96875\n",
      "100 0.859375\n",
      "110 0.9140625\n",
      "120 0.9140625\n",
      "130 0.9453125\n",
      "140 0.9296875\n",
      "150 0.9375\n",
      "160 0.8828125\n",
      "170 0.9140625\n",
      "180 0.90625\n",
      "190 0.9609375\n",
      "200 0.84375\n",
      "210 0.875\n",
      "220 0.8515625\n",
      "230 0.90625\n",
      "240 0.921875\n",
      "250 0.921875\n",
      "260 0.9296875\n",
      "270 0.8984375\n",
      "280 0.8671875\n",
      "290 0.921875\n",
      "300 0.9375\n",
      "310 0.8984375\n",
      "320 0.9296875\n",
      "330 0.890625\n",
      "340 0.9453125\n",
      "350 0.8828125\n",
      "360 0.9375\n",
      "370 0.8984375\n",
      "380 0.8515625\n",
      "390 0.8828125\n",
      "400 0.9140625\n",
      "410 0.8984375\n",
      "420 0.921875\n",
      "430 0.90625\n",
      "440 0.921875\n",
      "450 0.890625\n",
      "460 0.9453125\n",
      "Epoch #5\t Loss: 0.268753\tAccuracy: 0.906250\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=5 # or the number of times we go through our entire training dataset\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for (batch, (images, labels)) in enumerate(dataset):\n",
    "        train_loss, train_accuracy = model.train_on_batch(images, labels)\n",
    "    \n",
    "        if batch % 10 == 0: print(batch, train_accuracy)\n",
    "  \n",
    "    # Here you can gather any metrics or adjust your training parameters\n",
    "    print('Epoch #%d\\t Loss: %.6f\\tAccuracy: %.6f' % (epoch + 1, train_loss, train_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again to evaluate the model we need to check the accuracy on unseen or test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "O5ddqxgdVzQP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000==============================] - 1s 65us/sample - loss: 0.2813 - acc: 0.8969\n",
      "\n",
      "Test Model \t\t Loss: 0.281278\tAccuracy: 0.896900\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('\\nTest Model \\t\\t Loss: %.6f\\tAccuracy: %.6f' % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "5-conv-draft.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
